[tool.poetry]
name = "llama-summary"
version = "0.1.0"
description = ""
authors = ["conan_jung"]
readme = "README.md"
package-mode = false

[tool.poetry.dependencies]
python = "^3.10"
streamlit = "^1.36.0"
flask = "^3.0.3"
fastapi = "^0.111.1"
uvicorn = "^0.30.1"
gunicorn = "^23.0.0"
py-cpuinfo = "^9.0.0"
line_profiler = "^4.1.3"
wget = "^3.2"
awscli = "^1.34.7"
locust = "^2.29.1"
requests = "^2.32.3"
# langchain = "^0.2.5"
torch = { version = "^2.1.2+cpu", source = "torch" }
torchvision = { version = "^0.16.2+cpu", source = "torch" }
torchaudio = { version = "^2.1.2+cpu", source = "torch" }
wandb = "^0.17.3"
tiktoken = "^0.6.0"
blobfile = "^2.1.1"
tokenizers = "^0.19.0"
trl = "^0.9.6"
fairscale = "^0.4.13"
fire = "^0.6.0"
# transformers = "^4.40.0"
accelerate = "^0.29.2"
peft = "^0.11.1"
ray = { version = "^2.32.0",  extras = ["serve"] }
onnx = "^1.16.1"
onnxruntime = "^1.18.1"
openvino = "^2024.2.0"
# optimum = { version = "^1.21.2", extras = ["onnxruntime", "ipex", "openvino ", "habana", "neural-compressor", "diffusers"] }
# optimum-intel = { version = "^1.16.0", extras = ["extras"] }
# optimum-neuron = { version = "^0.0.23", extras = ["neuronx"] }
# optimum-neuron = { git = "https://github.com/ppijbb/optimum-neuron.git", branch = "main", extras = ["neuronx"] }
onnx2pytorch = "^0.4.1"
pyyaml = "^6.0.1"
setuptools-rust = "^1.9.0"
# ipex-llm = { version = "^2.1.0b20240801", extras = ["all"] }
# intel-extension-for-pytorch = { version = "^2.3.100+cpu", source = "intel" }
oneccl_bind_pt = { version = "^2.3.0", source = "intel" }
# protobuf = "^3.20.3"
nncf = "^2.11.0"
vllm = { version = "^0.2.7" }
bitsandbytes = "^0.43.1"
neuron = "8.2.6"
neuronx-cc = { version = "^2.11.0.35", source = "aws-neuron" }
torch-neuronx = { version = "2.1.2.2.2.0", source = "aws-neuron" }
libneuronxla = { version = "^2.0.965", source = "aws-neuron" }
transformers_neuronx = { version = "0.11.351", source = "aws-neuron" }
aws-neuronx-runtime-discovery = { version = "2.9", source = "aws-neuron" }


[[tool.poetry.source]]
name = "torch"
url = "https://download.pytorch.org/whl/cpu"
priority = "explicit"

[[tool.poetry.source]]
name = "intel"
url = "https://developer.intel.com/ipex-whl-stable-cpu/"
priority = "supplemental"

[[tool.poetry.source]]
name = "ipex-llm"
url = "https://pytorch-extension.intel.com/release-whl/stable/cpu/us/"
priority = "explicit"

[[tool.poetry.source]]
name = "aws-neuron"
url = "https://pip.repos.neuron.amazonaws.com"
priority = "supplemental"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
