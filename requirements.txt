python==3.10.*
streamlit==1.36.0
flask==3.0.3
fastapi==0.111.1
uvicorn==0.30.1
py-cpuinfo==9.0.0
line_profiler==4.1.3
locust==2.29.1
requests==2.32.3
langchain==0.2.5
wandb==0.17.3
tiktoken==0.6.0
blobfile==2.1.1
tokenizers==0.15.2
trl==0.9.6
fairscale==0.4.13
fire==0.6.0
transformers==4.36.2
accelerate==0.23.0
peft==0.11.1
ray[serve]==2.32.0
onnx==1.16.1
onnxruntime==1.18.1
openvino==2024.2.0
optimum[onnxruntime,ipex,openvino,neuronx,habana,furiosa,amd,neural-compressor]==1.14.0
optimum-intel[extras]==1.18.1
onnx2pytorch==0.4.1
pyyaml==6.0.1
setuptools-rust==1.9.0
protobuf==4.25.3
nncf==2.11.0
vllm==0.2.7
bitsandbytes==0.43.1
--extra-index-url https://download.pytorch.org/whl/cpu
torch==2.1.2+cpu
torchvision==0.16.2+cpu
torchaudio==2.1.2+cpu
--extra-index-url https://pytorch-extension.intel.com/release-whl/stable/cpu/us/
ipex-llm[all]==2.1.0b20240718
--extra-index-url https://developer.intel.com/ipex-whl-stable-cpu/
intel-extension-for-pytorch==2.3.100+cpu
oneccl_bind_pt==2.3.0
# --extra-index-url https://pip.repos.neuron.amazonaws.com
# neuronx-cc==2.13.66
# torch-neuronx==2.1.2.2.1.0
# libneuronxla==2.0.2335
# transformers_neuronx==0.9.474
# aws-neuronx-runtime-discovery==1.0