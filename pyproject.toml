[tool.poetry]
name = "llama-summary"
version = "0.1.0"
description = ""
authors = ["conan_jung"]
readme = "README.md"
package-mode = false

[tool.poetry.dependencies]
python = "^3.11"
streamlit = "^1.36.0"
transformers = "^4.36.2"
torch = { version = "^2.1.2+cpu", source = "torch" }
torchvision = { version = "^0.16.2+cpu", source = "torch" }
torchaudio = { version = "^2.1.2+cpu", source = "torch" }
langchain = "^0.2.5"
wandb = "^0.17.3"
flask = "^3.0.3"
fastapi = "^0.111.1"
uvicorn = "^0.30.1"
trl = "^0.9.6"
py-cpuinfo = "^9.0.0"
fairscale = "^0.4.13"
fire = "^0.6.0"
tiktoken = "^0.7.0"
blobfile = "^2.1.1"
accelerate = "^0.23.0"
peft = "^0.11.1"
ray = "^2.32.0"
onnx = "^1.16.1"
openvino = "^2024.2.0"
onnxruntime = "^1.18.1"
optimum-intel = { version = "^1.18.1", extras = ["extras"] }
onnx2pytorch = "^0.4.1"
pyyaml = "^6.0.1"
tokenizers = "^0.15.2"
setuptools-rust = "^1.9.0"
ipex-llm = { version = "^2.1.0b20240718", extras = ["all"] }
intel-extension-for-pytorch = { version = "^2.3.100+cpu", source = "intel" }
oneccl_bind_pt = { version = "^2.3.0", source = "intel" }

[[tool.poetry.source]]
name = "torch"
url = "https://download.pytorch.org/whl/cpu"
priority = "explicit"

[[tool.poetry.source]]
name = "intel"
url = "https://developer.intel.com/ipex-whl-stable-cpu/"
priority = "supplemental"

[[tool.poetry.source]]
name = "ipex-llm"
url = "https://pytorch-extension.intel.com/release-whl/stable/cpu/us/"
priority = "explicit"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
